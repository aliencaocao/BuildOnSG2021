{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Flatten, Add, concatenate, Dense, Conv2D, Dropout, BatchNormalization, Activation, AveragePooling2D, ZeroPadding2D, LeakyReLU\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Small\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(f'Running on Python {sys.version}, Tensorflow {tf.__version__}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DataPath = 'Dataset'\n",
    "maskImage = DataPath + '/with_mask'\n",
    "unmaskImage = DataPath + '/without_mask'\n",
    "data, labels = [], []\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "for imagePath in os.listdir(maskImage):\n",
    "    label = '1'  # with mask\n",
    "    image = load_img(os.path.join(maskImage,imagePath), target_size=(img_height, img_width))\n",
    "    # image = img_to_array(image)  # for v3 since v3 no need preprocess\n",
    "    image = preprocess_input(img_to_array(image))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "for imagePath in os.listdir(unmaskImage):\n",
    "    label = '0'  # without mask\n",
    "    image = load_img(os.path.join(unmaskImage,imagePath), target_size=(img_height, img_width))\n",
    "    # image = img_to_array(image)  # for v3 since v3 no need preprocess\n",
    "    image = preprocess_input(img_to_array(image))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = to_categorical(np.array(labels))\n",
    "assert len(data) == len(labels), 'Length of data and labels mismatch!'\n",
    "print(f'{len(data)} images loaded from {DataPath}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data, labels, test_size=0.15, stratify=labels, shuffle=True, random_state=69)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.20, stratify=train_y, shuffle=True, random_state=69)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ImageGen = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def h_swish(x):\n",
    "    return x * tf.nn.relu6(x+3) / 6  # replace with 0.16666667 if cant convert to tflite\n",
    "\n",
    "# Conv Block H-swish\n",
    "def CBH(x, filters, kernel_size, strides, padding=\"same\", zero_pad=False):\n",
    "    if zero_pad:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=1.001e-5)(x)\n",
    "    return h_swish(x)\n",
    "\n",
    "def ResUnit(x, filters, padding=\"same\", zero_pad=False):\n",
    "    xShort = x\n",
    "    x = CBH(x, filters, kernel_size=1, strides=1, padding=padding, zero_pad=zero_pad)\n",
    "    x = CBH(x, filters, kernel_size=3, strides=1, padding=padding, zero_pad=zero_pad)\n",
    "    return Add()([x, xShort])\n",
    "\n",
    "def CSP1_X(x, no, filters, strides, padding=\"same\", zero_pad=False):\n",
    "    xShort = x\n",
    "    x = CBH(x, filters=filters, kernel_size=1, strides=1, padding=padding, zero_pad=zero_pad)\n",
    "    for _ in range(no):\n",
    "        x = ResUnit(x, filters, padding, zero_pad)\n",
    "    x = Conv2D(filters, kernel_size=3, strides=strides, padding=padding)(x)\n",
    "    xShort = Conv2D(filters, kernel_size=1, strides=1, padding=padding)(xShort)\n",
    "    x = concatenate([x, xShort])\n",
    "    x = BatchNormalization(epsilon=1.001e-5)(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    return CBH(x, filters, kernel_size=1, strides=strides, padding=padding, zero_pad=zero_pad)\n",
    "\n",
    "def csp_darknet53(input_shape):\n",
    "    \"\"\"\n",
    "    CSPDarknet53 implementation based on AlexeyAB/darknet config\n",
    "    https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov4.cfg\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # First downsampling: L29 -> L103\n",
    "    x = conv_bn(inputs, filters=32, kernel_size=3, strides=1, activation=\"mish\")\n",
    "\n",
    "    # This block could be expressed as a CSPBlock with modification of num_filters in the middle\n",
    "    # For readability purpose, we chose to keep the CSPBlock as simple as possible and have a little redondancy\n",
    "    x = conv_bn(\n",
    "        x,\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        zero_pad=True,\n",
    "        padding=\"valid\",\n",
    "        activation=\"mish\",\n",
    "    )\n",
    "    route = conv_bn(x, filters=64, kernel_size=1, strides=1, activation=\"mish\")\n",
    "\n",
    "    shortcut = conv_bn(x, filters=64, kernel_size=1, strides=1, activation=\"mish\")\n",
    "    x = conv_bn(shortcut, filters=32, kernel_size=1, strides=1, activation=\"mish\")\n",
    "    x = conv_bn(x, filters=64, kernel_size=3, strides=1, activation=\"mish\")\n",
    "\n",
    "    x = x + shortcut\n",
    "    x = conv_bn(x, filters=64, kernel_size=1, strides=1, activation=\"mish\")\n",
    "    x = tf.keras.layers.Concatenate()([x, route])\n",
    "    x = conv_bn(x, filters=64, kernel_size=1, strides=1, activation=\"mish\")\n",
    "\n",
    "    # Second downsampling: L105 -> L191\n",
    "    x = csp_block(x, filters=128, num_blocks=2)\n",
    "\n",
    "    # Third downsampling: L193 -> L400\n",
    "    output_1 = csp_block(x, filters=256, num_blocks=8)\n",
    "\n",
    "    # Fourth downsampling: L402 -> L614\n",
    "    output_2 = csp_block(output_1, filters=512, num_blocks=8)\n",
    "\n",
    "    # Fifth downsampling: L616 -> L744\n",
    "    output_3 = csp_block(output_2, filters=1024, num_blocks=4)\n",
    "\n",
    "    return tf.keras.Model(inputs, [output_1, output_2, output_3], name=\"CSPDarknet53\")\n",
    "\n",
    "def conv_classes_anchors(inputs, num_anchors_stage, num_classes):\n",
    "    \"\"\"\n",
    "    Applies Conv2D based on the number of anchors and classifications classes, then reshape the Tensor.\n",
    "    TODO:  doubleCheck use_bias=True: is False in yolov3_tf2, is not specified in yolov4.cfg and True in pytorch yolov4.\n",
    "    Args:\n",
    "        inputs (tf.Tensor): 4D (N,H,W,C) input tensor\n",
    "        num_anchors_stage (int): Number of anchors for the given output stage\n",
    "        num_classes (int): Number of classes\n",
    "    Returns:\n",
    "        tf.Tensor: 5D (N,H,W,num_anchors_stage,num_classes+5) output tensor.\n",
    "            The last dimension contains the 4 box coordinates regression factors, the 1 objectness score,\n",
    "            and the num_classes confidence scores\n",
    "    \"\"\"\n",
    "    x = Conv2D(filters=num_anchors_stage * (num_classes + 5), kernel_size=1, strides=1, padding=\"same\", use_bias=True)(inputs)\n",
    "    x = tf.keras.layers.Reshape((x.shape[1], x.shape[2], num_anchors_stage, num_classes + 5))(x)\n",
    "    return x\n",
    "\n",
    "def yolov3_boxes_regression(feats_per_stage, anchors_per_stage):\n",
    "    \"\"\"\n",
    "    Applies the yolov4 box regression algorithm on the output of a stage.\n",
    "    Args:\n",
    "        feats_per_stage (tf.Tensor): 5D (N,grid_x,grid_y,num_anchors_per_stage,4+1+num_classes). The last dimension\n",
    "            consists in (x, y, w, h, obj, ...classes)\n",
    "        anchors_per_stage (numpy.array[int, 2]): List of 3 numpy arrays containing the anchor used for each stage.\n",
    "            The first and second columns respectively contain the anchors width and height.\n",
    "        (int): Maximum number of boxes predicted on each image (across all anchors/stages)\n",
    "    Returns:\n",
    "        List[tf.Tensor]: 4 Tensors respectively describing\n",
    "        bbox (N,grid_x,grid_y,num_anchors,4),\n",
    "        objectness (N,grid_x,grid_y,num_anchors,1),\n",
    "        class_probs (N,grid_x,grid_y,num_anchors,num_classes),\n",
    "    \"\"\"\n",
    "    grid_size_x, grid_size_y = feats_per_stage.shape[1], feats_per_stage.shape[2]\n",
    "    num_classes = feats_per_stage.shape[-1] - 5  # feats.shape[-1] = 4 + 1 + num_classes\n",
    "\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(feats_per_stage, (2, 2, 1, num_classes), axis=-1)\n",
    "\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "\n",
    "    grid = tf.meshgrid(tf.range(grid_size_y), tf.range(grid_size_x))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gy, gx, 1, 2]\n",
    "\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.constant([grid_size_y, grid_size_x], dtype=tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors_per_stage\n",
    "\n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs\n",
    "\n",
    "\n",
    "def yolo_nms(yolo_feats, yolo_max_boxes, yolo_iou_threshold, yolo_score_threshold):\n",
    "    \"\"\"\n",
    "    Applies the non max suppression to YOLO features and returns predicted boxes\n",
    "    Args:\n",
    "        yolo_feats (List[Tuple[tf.Tensor]]): For each output stage, is a 3-tuple of 5D tensors corresponding to\n",
    "            bbox (N,grid_x,grid_y,num_anchors,4),\n",
    "            objectness (N,grid_x,grid_y,num_anchors,4),\n",
    "            class_probs (N,grid_x,grid_y,num_anchors,num_classes),\n",
    "        yolo_max_boxes (int): Maximum number of boxes predicted on each image (across all anchors/stages)\n",
    "        yolo_iou_threshold (float between 0. and 1.): IOU threshold defining whether close boxes will be merged\n",
    "            during non max regression.\n",
    "        yolo_score_threshold (float between 0. and 1.): Boxes with score lower than this threshold will be filtered\n",
    "            out during non max regression.\n",
    "    Returns:\n",
    "        List[tf.Tensor]: 4 Tensors(N,yolo_max_boxes) respectively describing boxes, scores, classes, valid_detections\n",
    "    \"\"\"\n",
    "    bbox_per_stage, objectness_per_stage, class_probs_per_stage = [], [], []\n",
    "\n",
    "    for stage_feats in yolo_feats:\n",
    "        num_boxes = (\n",
    "            stage_feats[0].shape[1] * stage_feats[0].shape[2] * stage_feats[0].shape[3]\n",
    "        )  # num_anchors * grid_x * grid_y\n",
    "        bbox_per_stage.append(\n",
    "            tf.reshape(\n",
    "                stage_feats[0],\n",
    "                (tf.shape(stage_feats[0])[0], num_boxes, stage_feats[0].shape[-1]),\n",
    "            )\n",
    "        )  # [None,num_boxes,4]\n",
    "        objectness_per_stage.append(\n",
    "            tf.reshape(\n",
    "                stage_feats[1],\n",
    "                (tf.shape(stage_feats[1])[0], num_boxes, stage_feats[1].shape[-1]),\n",
    "            )\n",
    "        )  # [None,num_boxes,1]\n",
    "        class_probs_per_stage.append(\n",
    "            tf.reshape(\n",
    "                stage_feats[2],\n",
    "                (tf.shape(stage_feats[2])[0], num_boxes, stage_feats[2].shape[-1]),\n",
    "            )\n",
    "        )  # [None,num_boxes,num_classes]\n",
    "\n",
    "    bbox = tf.concat(bbox_per_stage, axis=1)\n",
    "    objectness = tf.concat(objectness_per_stage, axis=1)\n",
    "    class_probs = tf.concat(class_probs_per_stage, axis=1)\n",
    "\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.expand_dims(bbox, axis=2),\n",
    "        scores=objectness * class_probs,\n",
    "        max_output_size_per_class=yolo_max_boxes,\n",
    "        max_total_size=yolo_max_boxes,\n",
    "        iou_threshold=yolo_iou_threshold,\n",
    "        score_threshold=yolo_score_threshold,\n",
    "    )\n",
    "\n",
    "    return [boxes, scores, classes, valid_detections]\n",
    "\n",
    "def yolov3_head(\n",
    "    input_shapes,\n",
    "    anchors,\n",
    "    num_classes,\n",
    "    training,\n",
    "    yolo_max_boxes,\n",
    "    yolo_iou_threshold,\n",
    "    yolo_score_threshold,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the YOLOv3 head, which is used in YOLOv4\n",
    "    Args:\n",
    "        input_shapes (List[Tuple[int]]): List of 3 tuples, which are the output shapes of the neck.\n",
    "            None dimensions are ignored.\n",
    "            For CSPDarknet53+YOLOv4_neck, those are: [ (52, 52, 128), (26, 26, 256), (13, 13, 512)] for a (416,\n",
    "            416) input.\n",
    "        anchors (List[numpy.array[int, 2]]): List of 3 numpy arrays containing the anchor sizes used for each stage.\n",
    "            The first and second columns of the numpy arrays respectively contain the anchors width and height.\n",
    "        num_classes (int): Number of classes.\n",
    "        training (boolean): If False, will output boxes computed through YOLO regression and NMS, and YOLO features\n",
    "            otherwise. Set it True for training, and False for inferences.\n",
    "        yolo_max_boxes (int): Maximum number of boxes predicted on each image (across all anchors/stages)\n",
    "        yolo_iou_threshold (float between 0. and 1.): IOU threshold defining whether close boxes will be merged\n",
    "            during non max regression.\n",
    "        yolo_score_threshold (float between 0. and 1.): Boxes with score lower than this threshold will be filtered\n",
    "            out during non max regression.\n",
    "    Returns:\n",
    "        tf.keras.Model: Head model\n",
    "    \"\"\"\n",
    "    input_1 = tf.keras.Input(shape=filter(None, input_shapes[0]))\n",
    "    input_2 = tf.keras.Input(shape=filter(None, input_shapes[1]))\n",
    "    input_3 = tf.keras.Input(shape=filter(None, input_shapes[2]))\n",
    "\n",
    "    x = conv_bn(input_1, filters=256, kernel_size=3, strides=1, activation=\"leaky_relu\")\n",
    "    output_1 = conv_classes_anchors(\n",
    "        x, num_anchors_stage=len(anchors[0]), num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    x = conv_bn(\n",
    "        input_1,\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        zero_pad=True,\n",
    "        padding=\"valid\",\n",
    "        activation=\"leaky_relu\",\n",
    "    )\n",
    "    x = tf.keras.layers.Concatenate()([x, input_2])\n",
    "    x = conv_bn(x, filters=256, kernel_size=1, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=512, kernel_size=3, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=256, kernel_size=1, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=512, kernel_size=3, strides=1, activation=\"leaky_relu\")\n",
    "    connection = conv_bn(\n",
    "        x, filters=256, kernel_size=1, strides=1, activation=\"leaky_relu\"\n",
    "    )\n",
    "    x = conv_bn(\n",
    "        connection, filters=512, kernel_size=3, strides=1, activation=\"leaky_relu\"\n",
    "    )\n",
    "    output_2 = conv_classes_anchors(\n",
    "        x, num_anchors_stage=len(anchors[1]), num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    x = conv_bn(\n",
    "        connection,\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        zero_pad=True,\n",
    "        padding=\"valid\",\n",
    "        activation=\"leaky_relu\",\n",
    "    )\n",
    "    x = tf.keras.layers.Concatenate()([x, input_3])\n",
    "    x = conv_bn(x, filters=512, kernel_size=1, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=1024, kernel_size=3, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=512, kernel_size=1, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=1024, kernel_size=3, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=512, kernel_size=1, strides=1, activation=\"leaky_relu\")\n",
    "    x = conv_bn(x, filters=1024, kernel_size=3, strides=1, activation=\"leaky_relu\")\n",
    "    output_3 = conv_classes_anchors(\n",
    "        x, num_anchors_stage=len(anchors[2]), num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    if training:\n",
    "        return tf.keras.Model(\n",
    "            [input_1, input_2, input_3],\n",
    "            [output_1, output_2, output_3],\n",
    "            name=\"YOLOv3_head\",\n",
    "        )\n",
    "\n",
    "    predictions_1 = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolov3_boxes_regression(x_input, anchors[0]),\n",
    "        name=\"yolov3_boxes_regression_small_scale\",\n",
    "    )(output_1)\n",
    "    predictions_2 = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolov3_boxes_regression(x_input, anchors[1]),\n",
    "        name=\"yolov3_boxes_regression_medium_scale\",\n",
    "    )(output_2)\n",
    "    predictions_3 = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolov3_boxes_regression(x_input, anchors[2]),\n",
    "        name=\"yolov3_boxes_regression_large_scale\",\n",
    "    )(output_3)\n",
    "\n",
    "    output = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolo_nms(\n",
    "            x_input,\n",
    "            yolo_max_boxes=yolo_max_boxes,\n",
    "            yolo_iou_threshold=yolo_iou_threshold,\n",
    "            yolo_score_threshold=yolo_score_threshold,\n",
    "        ),\n",
    "        name=\"yolov4_nms\",\n",
    "    )([predictions_1, predictions_2, predictions_3])\n",
    "\n",
    "    return tf.keras.Model([input_1, input_2, input_3], output, name=\"YOLOv3_head\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}